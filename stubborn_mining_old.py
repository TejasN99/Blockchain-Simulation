import random as random_sample
from random import randint
from numpy import random
import sys
import heapq as hq
import os

# Global Variables to track txns and events
txn_count = 1
block_count = 0
event_count = 1

# Network Topology Params
PEER_CONN_MIN = 4
PEER_CONN_MAX = 7

# Minimum number of transactions in each block
MIN_TXNS_BLOCK = 5

adversary_blocks_public = []
adversary_blocks_private=[]

class Node:
    """
    A class to represent each Node

    Attributes
    ----------
    id : int
        The ID of each Node

    speed : str
        Denotes the speed of the node. "Slow" implies a slow node and "Fast" implies a fast node
    
    hash_power : str
        Denotes the hashing power of the node. "Low" implies a node with low hashing power and "High" implies a node with high hashing power
    
    unspent_txn_pool : list
        A list of transactions which stores the UTXO at the node

    seen_txn_ids : list
        A list of IDs of all the transactions generated or received by the node. Used for loopless forwarding of transactions

    leaf_blocks : list
        A list of Block objects, used to traverse the blockchain structure at the node

    mining_on : Block object
        Stores the block on which the node is currently mining on

    avg_mining_time : float
        Stores the average mining time of the node, calculated using its hashing power

    seen_block_id : list
        A list of IDs of all the blocks generated or received by the node. Used for loopless forwarding of blocks

    block_timestamp : dict
        Stores data about blocks generated or received by the node. Contains block IDs as the keys, and each value is a list, which stores the timestamp of generating the block, whether the block was generated by the block or received from another node and the block object. Used for logging
    """
    def __init__(self, id, speed, genesis_block, avg_mining_time):
        self.id = id
        self.speed = speed
        self.unspent_txn_pool = []
        self.seen_txn_id = []
        self.leaf_blocks = [genesis_block]
        self.mining_on = genesis_block
        self.avg_mining_time = avg_mining_time
        self.seen_block_id = []
        self.block_timestamp = {}


class Adversary(Node):
    def __init__(self, id, speed, genesis_block, avg_mining_time):
        Node.__init__(self, id, speed, genesis_block, avg_mining_time)
        self.pvt_chain = []
        self.lead = 0
        #Shashank: better to have at block level??
        self.public_release=0 


class Single_Transaction:
    """
    A class to represent each Transaction

    Attributes
    ----------
    id : int
        ID of the transaction

    payer : Node object 
        Stores the node object of the payer

    recipient : Node object 
        Stores the node object of the recipient

    amount : int
        The amount being transferred
    """
    def __init__(self, payer_node, recipient_node, amount):
        global txn_count
        self.id = txn_count
        self.payer = payer_node
        self.recipient = recipient_node
        self.amount = amount        
        txn_count += 1


class Block:
    """
    A class to represent each Block

    Attributes
    ----------
    id : int
        The ID of the block

    creator_node : Node object
        The node object of the node which created the block

    parent : Block object
        Stores the parent of the block

    balance_sheet : dict
        Stores the balance sheet at the block. Has node IDs as keys and the balance of the node as values
    """
    def __init__(self, creator_node, parent, txn_list, balance_sheet):
        global block_count
        self.id = block_count
        self.creator_node = creator_node
        self.parent = parent
        self.balance_sheet = balance_sheet

        self.adversary_release_status='private'   

        # block_count = 0 means Genesis block             
        if block_count == 0:
            self.chain_length = 0
            self.txn_list = [] 
            self.txns_in_blockchain = []
        else:
            self.chain_length = parent.chain_length + 1
            self.txn_list = txn_list
            self.txns_in_blockchain = parent.txns_in_blockchain + txn_list
        self.block_size = (1024*8) + (1024*8*len(txn_list))
        block_count += 1          


class Event:
    """
    A class to represent each Event

    Attributes
    ----------
    id : int
        ID of the Event

    execution_time : int
        The time in milliseconds from the starting of the program when the event should get executed

    event_type : str
        Denotes the type of event. Would contain one among the four values: generate_txn, generate_block, receive_txn, receive_block

    event_packet
        Stores the class object of the associated block or transaction

    src_node : Node object
        Stores the object that generated the event
    
    tgt_node : Node object
        Stores the recipient node, if the event is a receive event
    """
    def __init__(self, execution_time, event_type, event_packet, src_node, tgt_node = None):
        global event_count
        self.id = event_count
        self.execution_time = execution_time
        self.event_type = event_type
        self.event_packet = event_packet
        self.src_node = src_node
        self.tgt_node = tgt_node
        event_count += 1


def write_logs_for_nodes():
    """
    A function to write logs for the simulation
    A folder is created which contains:
    1) A log file for each node whose format is node_nodenum.txt where nodenum is the node number (e.g: node_1.txt, node_2.txt etc.)
    2) overall_stats.txt
    """
    log_folder = "Stubborn_Log_I_" + str(I) + "_ttx_" + str(ttx) + "_nodes_" + str(total_nodes) + "_z0_" + str(z0) + "_zeta_" + str(zeta) + "_TXNS_" + str(TOTAL_TXNS) +"alpha"+ str(alpha)

    log_folder_path = os.path.join(os. getcwd(), log_folder)
    if not os.path.exists(log_folder_path):
        os.makedirs(log_folder_path)

    # for i, node in enumerate(total_nodes, nodes.values()):
    for i in range(1, total_nodes+2):
        node = nodes[i]
        f = open(log_folder + "/node_" + str(i) + ".txt", "w")
        f.write("Node Type:\n")
        if node.speed == "Slow":
            f.write("Slow, ")
        else:
            f.write("Fast, ")
        # if node.hash_power == "Low":
        #     f.write("Low CPU Node\n\n")
        # else:
        #     f.write("High CPU Node\n\n")

        for block in node.block_timestamp:
            if node.block_timestamp[block][1] == 0:
                f.write("Received block: " + str(block) + " at " + str(node.block_timestamp[block][0]) + " with " + str(len(node.block_timestamp[block][2].txn_list)) + " transactions\n")
            else:
                f.write("Generated block: " + str(block) + " at " + str(node.block_timestamp[block][0]) + "\n")
        f.write("\nChains at node:\n")

        # Finding longest chain at the Node
        longest_chain_len = 0
        for leaf_block in node.leaf_blocks:
            longest_chain_len = max(longest_chain_len, leaf_block.chain_length)

            links = []
            chain = []
            cur_block = leaf_block
            while(cur_block.id != 0):
                chain.append(cur_block.id)
                if cur_block.parent.id == 0:
                    if ("G", cur_block.id) not in links:
                        links.append(("G", cur_block.id))
                elif (cur_block.id, cur_block.parent.id) not in links:
                    links.append((cur_block.parent.id, cur_block.id))
                cur_block = cur_block.parent                

            f.write("G ")
            for block_id in chain[::-1]:
                f.write("<- " + str(block_id) + " ")
            f.write("\n")
        
        f.write("Length of longest chain: " + str(longest_chain_len) + "\n\n")
        links = []
        f.close()

    print("Adversary blocks private:", str(adversary_blocks_private))
    print("Adversary blocks public:", str(adversary_blocks_public))
    

    f = open(log_folder + "/overall_stats.txt", "w")
    
    f.write("Number of nodes: " + str(total_nodes) + "\n")
    f.write("Avg. mining time: " + str(I) + "\n")
    f.write("Avg. time between transactions: " + str(ttx) + "\n")
    f.write("Percentage of slow nodes: " + str(z0) + "\n")

    #f.write("Percentage of High CPU nodes: " + str(z1) + "\n\n")

    for node in node_graph:
        f.write(str(node.id) + " -> ")
        peers = []
        for peer in node_graph[node]:
            peers.append(peer.id)
        f.write(",".join(str(node_id) for node_id in peers) + "\n")
    
    print("\n")

    node = nodes[total_nodes + 1]
    longest_leaf = node.leaf_blocks[0]
    for leaf_block in node.leaf_blocks[1:]:
        if leaf_block.chain_length > longest_leaf.chain_length:
            longest_leaf = leaf_block

    n_lowCPU = 0
    n_slow = 0

    block = longest_leaf
    tot_transaction = 0
    while(block.id != 0):
        # if block.creator_node.hash_power == "Low":
        #     n_lowCPU += 1
        if block.creator_node.speed == "Slow":
            n_slow += 1
        tot_transaction += len(block.txn_list)
        block = block.parent
    
    

    
    # prcnt_highCPU = (longest_leaf.chain_length - n_lowCPU) * 100 / longest_leaf.chain_length
    prcnt_fast = (longest_leaf.chain_length - n_slow) * 100 / longest_leaf.chain_length
    
    f.write("\nNumber of blocks in the longest chain: " + str(longest_leaf.chain_length) + "\n")
    #list(set()) to remove duplicates if any in the seen_block_id list
    f.write("Total number of blocks in blockchain: " + str(len(list(set(node.seen_block_id)))) + "\n")
    f.write("Avg. number of transactions per block: " + str(tot_transaction/longest_leaf.chain_length))
    # f.write("\nPercentage of blocks in the main chain generated by High CPU Nodes: " + str(prcnt_highCPU) + "\n")
    f.write("Percentage of blocks in the main chain generated by Fast Nodes: " + str(prcnt_fast))

    f.write("Adversary blocks private:" + str(adversary_blocks_private)+ "\n")
    f.write("Adversary blocks public:" + str(adversary_blocks_public)+ "\n")

    
    #Traversing the longest leaf to collect all block ids of the lingest block-chain
    block = longest_leaf
    longest_chain=[]
    while(block.id != 0):
        longest_chain.append(block.id)
        block=block.parent

    adv_blocks_in_chain=[]
    for block_id in adversary_blocks_public:
        if block_id in longest_chain:
              adv_blocks_in_chain.append(block_id)

    f.write("Num Blocks in longest chain is "+str(longest_leaf.chain_length)+ "\n")
    f.write("Num Adversary Blocks in longest chain is "+str(len(adv_blocks_in_chain))+ "\n")
    f.write("Num Adversary Blocks mined is "+ str(len(adversary_blocks_private))+ "\n")
    f.write("Num Adversary Blocks publicly released is "+ str(len(adversary_blocks_public))+ "\n")


    #Ratio1: #of adv block in blockchain /# of adv blocks mined
    ratio1=len(adv_blocks_in_chain)/len(adversary_blocks_private)*100
    f.write("Ratio1 is "+str(ratio1)+ "\n")

    #Ratio2:
    num_blocks_in_blockchain=longest_leaf.chain_length
    f.write("Num Blocks in longest chain is "+str(num_blocks_in_blockchain)+"\n")
    total_blocks_mined=len(list(set(node.seen_block_id)))
    f.write("Total blocks mined "+str(total_blocks_mined)+"\n")
    ratio2=num_blocks_in_blockchain/total_blocks_mined*100
    f.write("Ratio2 is "+str(ratio2)+ "\n")

    #%Reward
    perct_reward=len(adv_blocks_in_chain)/num_blocks_in_blockchain*100
    f.write("%Reward "+str(perct_reward)+ "\n")             

    
    f.close()

        
    
def generate_valid_txn_list(node):
    """
    A function which tries to genereate a valid set of transactions to form a block
    The transactions are picked from the UTXO Pool of the mining node
    Parameters
    ----------
    Node object that intends to mine a block

    Returns
    -------
    txn_list: A subset of transactions from the Node's UTXO that are valid
    balance_sheet: The updated balance sheet for each node after considering all the transactions
    of the blocks 
    """

    
    print("generate_valid_txn_list for node ",node.id)
    print("Length of unspent_txn_pool of node:",len(node.unspent_txn_pool))

    # If UTXO has number of transactions less than MIN_TXNS_BLOCK, block is not generated
    if len(node.unspent_txn_pool) < MIN_TXNS_BLOCK:        
        print("Stuck due to less txns in UTXO")
        print("Event_count",event_count)
        print("For node:", node.id, "\tlen of seen txn:", len(node.seen_txn_id))
        print("No. of total txns:", txn_count)
        
        # If the node has seen TOTAL_TXNS number of transactions but UTCO has less than MIN_TXNS_BLOCK number of transactions, we stop the simulation
        if len(node.seen_txn_id) >= TOTAL_TXNS:
            write_logs_for_nodes()
            exit()
        return None, None

    txns_valid_flag = 0
    no_of_attempts = 0
    max_no_of_attempts = 50 #UNDO
    while txns_valid_flag == 0 and no_of_attempts != max_no_of_attempts:
        #Pick min MIN_TXNS_BLOCK transactions and max 1023 or (length of UTXO) txns
        # num_txns = randint(MIN_TXNS_BLOCK, min(1023, len(node.unspent_txn_pool))) 
        num_txns = 5 ## UNDO
        txn_list = [node.unspent_txn_pool[i] for i in sorted(random_sample.sample(range(len(node.unspent_txn_pool)), num_txns))]
        balance_sheet = node.mining_on.balance_sheet.copy()
        txns_valid_flag = 1
        for txn in txn_list:
            if balance_sheet[txn.payer.id] < txn.amount:
                txns_valid_flag = 0
                break
            else:
                balance_sheet[txn.payer.id] -= txn.amount
                balance_sheet[txn.recipient.id] += txn.amount

        no_of_attempts += 1

    if txns_valid_flag == 0 and no_of_attempts == max_no_of_attempts:
        return None, None
    else:
        coinbase_txn = Single_Transaction(None, node, 50)
        print("Coinbase generated with ID", coinbase_txn.id)
        txn_list.append(coinbase_txn)
        balance_sheet[node.id] += 50    # Coinbase txn
        return txn_list, balance_sheet

def network_topology():
    #Creating a random network of nodes and checking if it connected or not 
    connected=False
    while not (connected):
        # Dictionary for number of nodes connected to each node
        node_connections = {}
        node_graph = {}
        # Initializing peer nodes to be empty for all nodes
        # +1 for adversary (below)
        for i in range(total_nodes + 1):
            node_graph[i+1] = []
        
        #Decide connections for all except adversary node
        for i in range(total_nodes):
            # Number of nodes connected to each node
            node_connections[i+1] = randint(PEER_CONN_MIN, PEER_CONN_MAX)
            count = len(node_graph[i+1])
            while count < node_connections[i+1]:
                node_num = randint(1,total_nodes)
                while len(node_graph[node_num]) >= PEER_CONN_MAX or node_num == (i+1) or node_num in node_graph[i+1]:
                    node_num = randint(1,total_nodes)

                #Add edges for both nodes since it is an undirected graph
                node_graph[i+1].append(node_num)
                node_graph[node_num].append(i+1)
                count = count+1
        
        # Creating connections for adversary node
        node_connections[total_nodes + 1] = total_nodes * zeta // 100
        adversary_peers = random_sample.sample(range(1,total_nodes+1), node_connections[total_nodes + 1])
        for node_no in adversary_peers:
            #Add edges for both nodes since it is an undirected graph
            node_graph[total_nodes + 1].append(node_no)
            node_graph[node_no].append(total_nodes + 1)

        #Returns True or None 
        connected = check_connectedness([],node_graph,1,total_nodes + 1)
    
    no_of_slow_nodes = total_nodes * z0 // 100
    slow_nodes = random_sample.sample(range(1,total_nodes+1), no_of_slow_nodes)

    node_speed = {}
    for i in range(1, total_nodes+1):
            if i in slow_nodes:
                node_speed[i] = 'Slow'
            else:
                node_speed[i] = 'Fast'

    #Adversary node is assumed to be Fast
    node_speed[total_nodes+1]='Fast'           
    
    #Initial Node Balances
    init_node_bal = {}
    for i in range(total_nodes+1): #+1 for adversary node
        init_node_bal[i+1] = randint(1000,10000)

    return node_graph, node_speed, init_node_bal  


def gen_initial_txns():
    """
    Generates the initial transactions for each node, with the inter-arrival between transactions generated by any peer chosen from an exponential distribution whose mean time is Ttx

    Parameters
    ----------

    Returns
    -------
    event_list : list
        List of the initial transactions with their time of exexcution
    """

    global nodes
    global txn_count
    global event_count

    event_list = []

    # Minimal execution_time difference to sort event_list
    c = 0
    #nodes is a dictionary with key=node_num and value = node object
    for node in nodes.values():     
        payer_node_id = node.id
        recipient_node_id = randint(1,total_nodes+1)
        while (recipient_node_id == payer_node_id):
            recipient_node_id = randint(1,total_nodes+1)
        amount = randint(1,20)
        txn = Single_Transaction(nodes[payer_node_id], nodes[recipient_node_id], amount)
        print("Txnid",txn_count,"Node ", payer_node_id," pays","Node ",recipient_node_id," ",amount," BTC$")

        txn_event = Event(c, "generate_txn", txn, nodes[payer_node_id])
        print("Event Count:generate_txn",event_count)
        
        # Global list containing list of events
        # Add time-stamp concept and event listed to be always sorted by time stamp
        hq.heappush(event_list,(c,txn_event))
        c += 1
    return event_list


def start_mining(event_list, ttx):
    
    """
    The function adds a mining event for each node in the network

    Parameters
    ----------
    event_list : list
        List of events that has already been generated. The generate_block events are appended to this list.

    ttx : int
        Avg delay between generating transactions
    """
    c = 0
    for node in nodes.values():
        retry_mining_event = Event(ttx + c, "retry_mining", None, node)
        print("Event Count:retry_mining",event_count)
        hq.heappush(event_list, (ttx + c, retry_mining_event))
        c += 1    

def check_connectedness(visited_nodes,node_graph,current_node,total_nodes):
    """
    The function checks if node graph is connected or not by performing a DFS on it

    Parameters
    ----------
    visited_nodes: A list of node ids that have already been visited
    node_graph: A dictionary with key as node id and value is a list of peer node ids
    current_node: The node on which DFS is run
    total_nodes: Total Nodes in the setup
    Returns
    ----------
    True: If graph is connected
    False: Otherwise
    """
    if current_node not in visited_nodes:
        visited_nodes.append(current_node)
        for peer_node in node_graph[current_node]:
            check_connectedness(visited_nodes,node_graph,peer_node,total_nodes)            
    
    if len(visited_nodes) == total_nodes:
        return True

def latency(sender_node,receiver_node,message_bits):
    """
    Function calculates the time delay of sending a packet from one node to the other node 

    Parameters
    ----------
    sender_node:Node object from which packet is sent
    receiver_node:Node object receiving the packet
    message_bits: Packet size 
    
    Returns
    ----------
    The delay of packet in ms
    """
    if sender_node.speed == 'Fast' and receiver_node.speed == 'Fast':
        link_speed = 100
    else:
        link_speed = 5
    light_delay = randint(10,500)
    queue_delay = random.exponential(scale = 96/(link_speed * (2**10)))

    # light_delay is in ms, converting link_speed to bits/sec, later converting resulting time from s to ms, similarly converting queue_delay from s to ms
    overall_delay = light_delay + (message_bits/(link_speed*(2**20))) * 1000 + queue_delay * 1000
    return overall_delay

def restart_mining(node, event_list, new_block, cur_execution_time):
    """
    Function is used to make a node restart mining on a different block, if a longer chain is detected while receiving a new block

    Parameters
    ----------
    node : Node object
        The node which would restart its mining
    
    event_list : list
        The list of all events
    
    new_block : Block object
        The new_block on which the node would restart its mining

    cur_execution_time : float
        The current execution time    
    """

    # Stopping the current mining event of the node
    for event in event_list:
        if event[1].src_node == node and event[1].event_type == "generate_block":
            event_list.remove(event)
            hq.heapify(event_list)
            break

    # Changes the block being mined on to the new block and adds a new mining event
    node.mining_on = new_block
    txn_list, new_balance_sheet = generate_valid_txn_list(node)
    if txn_list == None:
        retry_mining_event = Event(cur_execution_time + 5*ttx, "retry_mining", None, node)
        print("Event Count:retry_mining",event_count)
        hq.heappush(event_list, (cur_execution_time + 5*ttx, retry_mining_event))
    else:
        mining_time = random.exponential(scale = node.avg_mining_time)
        execution_time = cur_execution_time + mining_time
        new_block = Block(node, node.mining_on, txn_list, new_balance_sheet)
        mining_event = Event(execution_time, "generate_block", new_block, node)
        print("Event Count:generate_block",event_count)
        hq.heappush(event_list,(execution_time, mining_event))


def event_handler(event_list, event, ttx):
    """
    A function that traverses a min heap: event_list (Top element is a the event with min timestamp)
    and handles events case-wise.
    Parameters
    ----------
    event_list: A min heap containing a list of tuple: 1st element is timestamp and 2nd element is the event object 

    event: The event object 

    ttx: Average interarrival time between two transactions
    """

    global event_count
    c=0 
    # Handling a generate_txn event indicates that a particular node has just generated a transaction 
    if event.event_type == "generate_txn":
        global txn_count        
        print("Detected Generate_txn")
        src_node=event.src_node
        src_node.seen_txn_id.append(event.event_packet.id)
        src_node.unspent_txn_pool.append(event.event_packet)
        print("Generate Txn: Appended to UTXO of source node ",src_node.id)
        print("Length of UTXO is",len(src_node.unspent_txn_pool))
        for peer_node in node_graph[src_node]:
            # Message size of single trasaction is 1024*8 bits
            prev_execution_time = event.execution_time
            latency_delay = latency(src_node,peer_node,1024*8)
            execution_time = prev_execution_time+latency_delay
            event_packet = event.event_packet
            receive_event = Event(execution_time,"receive_txn",event_packet,src_node,peer_node)
            print("Event Count:receive_txn",event_count)
            hq.heappush(event_list,(execution_time,receive_event))
        
        # We stop spawning transactions at 4 * TOTAL_TXNS so that the network is not flooded with transactions and hence simulation could end
        if txn_count > 2 * TOTAL_TXNS:
            print("Txn Count limit reached, stopping generation of txns")
            return

        # One generate_txn event spawns the next generate_txn event from the same node
        payer_node_id = src_node.id
        recipient_node_id = randint(1,total_nodes+1)
        while (recipient_node_id == payer_node_id):
            recipient_node_id = randint(1,total_nodes+1)
        amount = randint(1,20)
        txn = Single_Transaction(nodes[payer_node_id], nodes[recipient_node_id], amount) 
        new_txn_duration = random.exponential(scale = ttx)
        new_txn_event = Event(event.execution_time + new_txn_duration, "generate_txn", txn, nodes[payer_node_id])
        print("Event Count:generate_txn",event_count)
        hq.heappush(event_list,(event.execution_time + new_txn_duration,new_txn_event))

    # Handing a generate_block event would indicate that a node has completed its mining
    elif event.event_type == "generate_block":     
        src_node = event.src_node
        new_block = event.event_packet
        
        #Append for seen_block_id for Honest Node or Adversary Privately Mined
        #No need for Adversary Public Release
        if not isinstance(src_node,Adversary) or (isinstance(src_node,Adversary) and new_block.adversary_release_status=='private'):
            src_node.seen_block_id.append(new_block.id)

        if isinstance(src_node,Adversary):
            if (new_block.adversary_release_status=='public'):
                adversary_blocks_public.append(new_block.id)
            else:
                adversary_blocks_private.append(new_block.id)

            print("Inside generate_block of Adversry Node",src_node.id,"with block id",new_block.id)
            print("Lead",src_node.lead)
            print("Adversary_release_status",new_block.adversary_release_status)
            print("Pvt Chain length",len(src_node.pvt_chain))

        # 1 in block_timestamp means block generated by the same node. block_timestamp is used only for logging
        src_node.block_timestamp[new_block.id] = [event.execution_time, 1, new_block]
        print("Detected Generate_block",new_block.id, "from node",event.src_node.id)
        
        
        if not isinstance(src_node,Adversary) or (isinstance(src_node,Adversary) and new_block.adversary_release_status=='private'):
            
            #1.
            #Shashank: src_node.mining_on will change for both honest and adversary nodes which have privately mined
            #Adversary Nodes who have publicly released a block will keep on mining on the private chain. So NO change for them
            src_node.mining_on = new_block
            
            #2.
            #Similarly txn removal from UTXO happens only for Honest and Adversary Privaely Mined
            #Adversary Public Release need not do it
            print("Number of txns in block:", len(new_block.txn_list))
            print("UTXO Length b4 block generation",len(src_node.unspent_txn_pool))

            # Removing the txns in new block from the node's unspent_txn_pool
            for txn in new_block.txn_list:
                if txn in src_node.unspent_txn_pool:
                    src_node.unspent_txn_pool.remove(txn)
                    print("Removed from UTXO Txn id",txn.id)

            print("UTXO Length after block generation",len(src_node.unspent_txn_pool))


            #3. New "generate_txn" triggered only for Honest and Adversary Privately Mined
            # Adversary Public Release need not do it
            new_txn_list, balance_sheet = generate_valid_txn_list(src_node)
            # generate_valid_txn_list function returns None when either the UTXO has too less number of transactions, or when a valid transaction list couldn't be generated
            if new_txn_list == None:
                retry_mining_event = Event(5*ttx + event.execution_time, "retry_mining", None, src_node)
                print("Event Count:retry_mining",event_count)
                hq.heappush(event_list, (5*ttx + event.execution_time, retry_mining_event))
            else:
                next_block = Block(src_node, src_node.mining_on, new_txn_list, balance_sheet)
                print("Node", src_node.id,"started mining new block")
                mining_duration = random.exponential(scale = src_node.avg_mining_time)
                new_mining_event = Event(event.execution_time + mining_duration, "generate_block", next_block, src_node)
                print("Event Count",event_count,":generate_block scheduled at node",src_node.id)
                hq.heappush(event_list,(event.execution_time + mining_duration, new_mining_event))
        
        
        
        
        if not isinstance(src_node,Adversary) or (isinstance(src_node,Adversary) and new_block.adversary_release_status=='public'):

            try:
                #Under try block: Because in case of Aversary Node Public Release, src_node.mining_on
                #might not be a part of src_node.leaf_blocks
                src_node.leaf_blocks.remove(src_node.mining_on)
            except:
                None
            src_node.leaf_blocks.append(new_block)
            
            
            #Trigger Receive block for peers only if Honest Node has mined or Adversary has publicly released an old mined block
            # Triggering Receive Block Event to all the node peers
            for peer_node in node_graph[src_node]:
                prev_execution_time = event.execution_time
                latency_delay = latency(src_node, peer_node, new_block.block_size)
                execution_time = prev_execution_time + latency_delay
                receive_event = Event(execution_time,"receive_block",new_block,src_node,peer_node)
                print("Event Count:receive_block",event_count)
                hq.heappush(event_list,(execution_time,receive_event))
        
        #Case:Adversary Node has privately mined
        #We dont trigger receive block to peers
        else:
            print("Adversary Node",src_node.id,"has privately mined block",new_block.id)
            src_node.lead+=1
            src_node.pvt_chain.append(new_block)    


    # Handing a receive_txn event would indicate that a node has received a transaction. It spawns more receive_txn events so as to forward the transaction
    elif event.event_type == "receive_txn":
        # The target node of previous event is the source node for the next receive event triggered
        src_node = event.tgt_node
        prev_src_node = event.src_node
        print("Detected Receive_txn from node",prev_src_node.id,"to node ",src_node.id)

        # Forwarding the transaction looplessly
        if (event.event_packet.id not in src_node.seen_txn_id):
            src_node.seen_txn_id.append(event.event_packet.id)
            if event.event_packet not in src_node.unspent_txn_pool:
                print("Inside receive_txn, appending txn to unspent_txn_pool")
                src_node.unspent_txn_pool.append(event.event_packet)
                print("Receive Txn: Appended to UTXO of source node ",src_node.id)
                print("Length of UTXO is",len(src_node.unspent_txn_pool))
            else:
                print("Receive Txn: Txn already in UTXO")
            for peer_node in node_graph[src_node]:
                if (peer_node.id != prev_src_node.id):
                    # Message size of single trasaction is 1024*8 bits
                    prev_execution_time = event.execution_time
                    latency_delay = latency(src_node,peer_node,1024*8)
                    execution_time = prev_execution_time+latency_delay
                    event_packet = event.event_packet
                    receive_event = Event(execution_time,"receive_txn",event_packet,src_node,peer_node)
                    print("Event Count:receive_txn",event_count)
                    hq.heappush(event_list,(execution_time,receive_event))

    # Handing a receive_txn event would indicate that a node has received a new block. It spawns more receive_block events so as to forward the block
    elif event.event_type == "receive_block":
        # Checking if the block received is already in blockchain of the node
        prev_src_node = event.src_node
        src_node = event.tgt_node
        new_block = event.event_packet
        cur_time = event.execution_time

        if isinstance(src_node,Adversary):
            print("Inside receive_block of Adversary Node",src_node.id)
            print("Lead",src_node.lead)
            print("Adversary_release_status",new_block.adversary_release_status)
            print("Pvt Chain length",len(src_node.pvt_chain))

        print("Detected Receive block",new_block.id, "from node",prev_src_node.id,"to node ",src_node.id)

        # Forwarding the block looplessly
        if new_block.id not in src_node.seen_block_id:
            src_node.seen_block_id.append(new_block.id)

            # 0 in block_timestamp means block generated by another node, block_timestamp is used only for logging
            src_node.block_timestamp[new_block.id] = [cur_time, 0, new_block]
            if new_block.parent in src_node.leaf_blocks:
                src_node.leaf_blocks.remove(new_block.parent)
            src_node.leaf_blocks.append(new_block)
            
            # Receive Block triggered for all peers only for Honest Nodes
            #DO NOT Forward if received at Adversary Node
            if not isinstance(src_node,Adversary):
                for peer_node in node_graph[src_node]:
                    if (peer_node.id != prev_src_node.id):
                        print("Generating receive block from node ",src_node.id,"to peer node ",peer_node.id)                
                        latency_delay=latency(src_node,peer_node,new_block.block_size)
                        execution_time = cur_time + latency_delay
                        print("New exec time of event is",execution_time)
                        print("Latency between",src_node.id," ",peer_node.id,"is ",latency_delay)
                        receive_event = Event(execution_time,"receive_block", new_block, src_node, peer_node)
                        print("Event Count:receive_block",event_count)
                        hq.heappush(event_list,(execution_time,receive_event))
                    else:
                        print("Not sending receive block from node ",src_node.id,"to peer node ",peer_node.id,"since packet came from there!")
            else:
                #Adversary Node 
                print("Adversary node",src_node.id,"received an honest block",new_block.id)
                if (src_node.mining_on.chain_length-new_block.chain_length <src_node.lead):
                    
                    if (src_node.lead!=0):
                        print("Lead=",src_node.lead)
                        src_node.lead-=1
                        #Release first block of private chain officially
                        pvt_block=src_node.pvt_chain[0]
                        src_node.pvt_chain=src_node.pvt_chain[1:]
                        pvt_block.adversary_release_status='public'
                        print("Node", src_node.id,"publicly releases a private block",pvt_block.id, "as Honest Miners reduced lead by 1")
                        
                        new_mining_event = Event(event.execution_time +1, "generate_block", pvt_block, src_node)
                        print("Event Count",event_count,"publicly releases a private block",pvt_block.id, "as Honest reduced lead by 1",src_node.id)
                        hq.heappush(event_list,(event.execution_time +1, new_mining_event))    
                    
                    
            # If the new block is connected to the block curently being mined on, we remove transactions in the new block from UTXO and restart mining on the new block
            if new_block.parent == src_node.mining_on:
                for txn in new_block.txn_list:
                    if txn in src_node.unspent_txn_pool:
                        src_node.unspent_txn_pool.remove(txn)
                restart_mining(src_node, event_list, new_block, event.execution_time)

            # If the new block is a fork and the chain length is greater
            elif new_block.chain_length > src_node.mining_on.chain_length:
                current_mining_chain = []
                block = src_node.mining_on
                while(block.id != 0):
                    current_mining_chain.append(block)
                    block = block.parent

                new_block_chain = []
                block = new_block
                while(block.id != 0):
                    new_block_chain.append(block)
                    block = block.parent

                if current_mining_chain != []:
                    print("len of current_mining_chain:", len(current_mining_chain))
                    print("len of new_block_chain:", len(new_block_chain))
                    while(current_mining_chain[-1] == new_block_chain[-1]):
                        del current_mining_chain[-1]
                        del new_block_chain[-1]
                        
                        if current_mining_chain == []:
                            break

                # We backtrack the blockchain from the current chain to the new longer chain. Transactions from the current chain are added back to the UTXO and transactions from the new chain are removed from the UTXO of the node
                for block in current_mining_chain:
                    for txn in block.txn_list:
                        if txn in src_node.seen_txn_id:
                            src_node.unspent_txn_pool.append(txn)
                for block in new_block_chain:
                    for txn in block.txn_list:
                        if txn in src_node.unspent_txn_pool:
                            src_node.unspent_txn_pool.remove(txn)
                
                # Killing the current mining of the node since longer chain was found
                restart_mining(src_node, event_list, new_block, event.execution_time)
            
             
    # retry_mining event is used to check if the UTXO currently has enough transactions to start mining a block
    elif event.event_type == "retry_mining":
        src_node = event.src_node

        # if isinstance(src_node,Adversary):

        cur_time = event.execution_time        
        txn_list, new_balance_sheet = generate_valid_txn_list(src_node)
                
        if txn_list == None:
            # UTXO still doesn't have enough transactions, hence add another retry_mining event to event_list
            retry_mining_event = Event(cur_time + 5*ttx, "retry_mining", None, src_node)
            print("Event Count:retry_mining",event_count)
            hq.heappush(event_list, (cur_time + 5*ttx, retry_mining_event))
        else:
            # generating transaction list for block was successful, hence start mining
            mining_time = random.exponential(scale = src_node.avg_mining_time)
            execution_time = cur_time + mining_time
            new_block = Block(src_node, src_node.mining_on, txn_list, new_balance_sheet)
            mining_event = Event(execution_time, "generate_block", new_block, src_node)
            print("Event Count:generate_block",event_count)
            hq.heappush(event_list,(execution_time, mining_event))


z0 = int(sys.argv[1])           # Percentage of slow nodes
# z1 = int(sys.argv[2])           # Percentage of low CPU nodes
ttx = int(sys.argv[2])          # Avg. inter-arrival time between transactions of each node
I = int(sys.argv[3])            # Avg. mining time of a block across the network
total_nodes = int(sys.argv[4])  # Total number of honest nodes in the network
TOTAL_TXNS = int(sys.argv[5])   # Termination criteria
alpha = float(sys.argv[6])      # Fraction of mining power of adversary
zeta = int(sys.argv[7])         # Percentage of nodes the adversary is connected to


node_graph,node_speed,init_node_bal = network_topology()

print("Network Topology Generation Complete")

genesis_block = Block(None, None, [], init_node_bal)
node_hashing_power = (1 - alpha)/total_nodes

# Initialzing Nodes:
nodes={}
for i in range(total_nodes):    
    nodes[i+1] = Node(i+1, node_speed[i+1],  genesis_block, I/node_hashing_power)
nodes[total_nodes + 1] = Adversary(total_nodes+1, 'Fast',  genesis_block, I/alpha)

print("Total no. of nodes including adversary:", total_nodes + 1)

# Replacing node IDs in node_graph with the node objects
for id in range(1, total_nodes + 2):
    peer_nodes = []
    for peer_id in node_graph[id]:
        peer_nodes.append(nodes[peer_id])
    node_graph[nodes[id]] = peer_nodes
    del node_graph[id]


if __name__ == "__main__":    
    event_list = gen_initial_txns()
    start_mining(event_list, ttx)
    print("Added initial transaction and mining events!")

    ## Event Handler driver code
    while (len(event_list)!=0):
        # Popping the event with the least execution time and handling the event
        # Each event in event_list is a tuple of the form (execution_time, Event Object)
        event  = hq.heappop(event_list)[1]
        event_handler(event_list, event, ttx)